{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "- To check data and model if it preditcs or not.\n",
    "- This is only for intent dataset\n",
    "- Model implemented in for 8640 data samples after filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Import Key Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('file_clean_intent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dep.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=data['dep'].value_counts()\n",
    "df = data.loc[data['dep'].isin(counts.index[counts > 150])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9477, 4)\n",
      "(8640, 4)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dep.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeat=[\"Order management\",\"product complaints - products (Reklamation Produkte)\",\"Software/Webshop/App\",\n",
    "        \"Shipping issues\",\"Customer feedback\",\"ShareWithSaal\",\"Payment (Bezahlung)\",\n",
    "        \"product complaints - colours (Reklamation Farben)\",\"Product (Produkt)\",\"Marketing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['clean'] = df['firstmessage'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.70)\n",
    "train_posts = df['clean'][:train_size]\n",
    "train_tags = df['dep'][:train_size]\n",
    "\n",
    "test_posts = df['clean'][train_size:]\n",
    "test_tags = df['dep'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6048,)\n"
     ]
    }
   ],
   "source": [
    "print(train_posts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "tokenize = text.Tokenizer(num_words=max_words,char_level=False)\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6048, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags) \n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1 #strings start from 0 index. To count them from 1-10\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6048, 10)\n",
      "(2592, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "shape_of_input=max_words # 10000 words\n",
    "EMBEDDING_DIM=10000\n",
    "MAX_NB_WORDS = 5000# The maximum number of words to be used. (most frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.Defining Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 512))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dropout(.2))#The dropout rate is set to 20%, meaning one in 5 inputs will be randomly excluded from each update cycle\n",
    "model.add(keras.layers.Dense(512,kernel_initializer='uniform', input_shape=(shape_of_input,), activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(.2))\n",
    "model.add(keras.layers.Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom keras.layers import Dense, Embedding\\nmodel = Sequential()\\nmodel.add(Embedding(MAX_NB_WORDS,EMBEDDING_DIM, input_length=max_words))\\nmodel.add(Dense(512, activation=\"relu\"))\\nmodel.add(Dropout(0.2))#The dropout rate is set to 20%, meaning one in 5 inputs will be randomly excluded from each update cycle\\n#model.add(Dense(num_classes)) # there are 10 classes i.e at output layer\\n#model.add(Activation(\\'softmax\\'))\\nmodel.add(Dense(10, activation=\\'softmax\\'))\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "from keras.layers import Dense, Embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS,EMBEDDING_DIM, input_length=max_words))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))#The dropout rate is set to 20%, meaning one in 5 inputs will be randomly excluded from each update cycle\n",
    "#model.add(Dense(num_classes)) # there are 10 classes i.e at output layer\n",
    "#model.add(Activation('softmax'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 512)         5120000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 5,387,786\n",
      "Trainable params: 5,387,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding summary table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At embedding step: 512 (Dense layer size) multiple by 10,000(dimension that we decide for embedding layer). embedding layer is vectorization form of what we have in BOW or TFIDF. We can reduce this dimension as well.\n",
    "- At Dense step: 512 (Output coming from embedding layer) multiple by 512(Hidden layer with size 512.)+ biase(of all 512 neuron on input of hidden layer).\n",
    "- At dense_1(Dense): 512(Output coming from hidden layer) multiply by 10(number of classes at output layer) + bias(10 neurons of output layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.Fit the model on given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5443 samples, validate on 605 samples\n",
      "Epoch 1/10\n",
      "5443/5443 [==============================] - 154s 28ms/sample - loss: 1.7093 - accuracy: 0.5058 - val_loss: 1.5593 - val_accuracy: 0.6083\n",
      "Epoch 2/10\n",
      "5443/5443 [==============================] - 154s 28ms/sample - loss: 1.6898 - accuracy: 0.5074 - val_loss: 1.5522 - val_accuracy: 0.6083\n",
      "Epoch 3/10\n",
      "5443/5443 [==============================] - 152s 28ms/sample - loss: 1.6848 - accuracy: 0.5074 - val_loss: 1.5534 - val_accuracy: 0.6083\n",
      "Epoch 4/10\n",
      "5443/5443 [==============================] - 151s 28ms/sample - loss: 1.6858 - accuracy: 0.5074 - val_loss: 1.5633 - val_accuracy: 0.6083\n",
      "Epoch 5/10\n",
      "5443/5443 [==============================] - 151s 28ms/sample - loss: 1.6885 - accuracy: 0.5074 - val_loss: 1.5484 - val_accuracy: 0.6083\n",
      "Epoch 6/10\n",
      "5443/5443 [==============================] - 154s 28ms/sample - loss: 1.6849 - accuracy: 0.5074 - val_loss: 1.5398 - val_accuracy: 0.6083\n",
      "Epoch 7/10\n",
      "5443/5443 [==============================] - 158s 29ms/sample - loss: 1.6847 - accuracy: 0.5074 - val_loss: 1.5323 - val_accuracy: 0.6083\n",
      "Epoch 8/10\n",
      "5443/5443 [==============================] - 157s 29ms/sample - loss: 1.6837 - accuracy: 0.5074 - val_loss: 1.5422 - val_accuracy: 0.6083\n",
      "Epoch 9/10\n",
      "5443/5443 [==============================] - 155s 28ms/sample - loss: 1.6812 - accuracy: 0.5074 - val_loss: 1.5413 - val_accuracy: 0.6083\n",
      "Epoch 10/10\n",
      "5443/5443 [==============================] - 158s 29ms/sample - loss: 1.6773 - accuracy: 0.5074 - val_loss: 1.5547 - val_accuracy: 0.6083\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing has improved from previous model, there is no overfitting pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.63117284\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.<br>\n",
    "\n",
    "- verbose=0 will show you nothing (silent)\n",
    "\n",
    "- verbose=1 will show you an animated progress bar like this:<br>\n",
    "\n",
    "progres_bar with multiple ==== signs\n",
    "\n",
    "- verbose=2 will just mention the number of epoch like this:<br>\n",
    "\n",
    "epoch 1/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08468376, 0.00679529, 0.46304205, 0.03076926, 0.0301506 ,\n",
       "        0.06118688, 0.07317071, 0.1196486 , 0.03500771, 0.09554515],\n",
       "       [0.08561262, 0.00705099, 0.4536532 , 0.0301964 , 0.03051176,\n",
       "        0.06214548, 0.07160873, 0.12170194, 0.03570114, 0.10181777],\n",
       "       [0.08643577, 0.00729134, 0.4448939 , 0.02965755, 0.03083036,\n",
       "        0.06299645, 0.07019007, 0.12352511, 0.03633162, 0.10784781],\n",
       "       [0.08609706, 0.00719228, 0.44847423, 0.02987925, 0.03070114,\n",
       "        0.06265538, 0.07074905, 0.12279896, 0.03607405, 0.10537864],\n",
       "       [0.08382985, 0.00657736, 0.47106797, 0.03125318, 0.02981613,\n",
       "        0.06034839, 0.07448908, 0.11782965, 0.03439392, 0.09039451]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.prediction classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict crisp classes for test set. Output will be 1-D\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 8, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true claesses\n",
    "y_test_class[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted classes\n",
    "y_pred_class[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.weight performance of each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 512)\n",
      "(512, 512)\n",
      "(512,)\n",
      "(512, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "for w in model.get_weights():\n",
    "    print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding/embeddings:0' shape=(10000, 512) dtype=float32, numpy=\n",
       " array([[ 0.00125986,  0.00476757, -0.00100097, ...,  0.00388782,\n",
       "         -0.00341592,  0.00172112],\n",
       "        [ 0.41888887,  0.812841  ,  0.39719784, ..., -0.43757677,\n",
       "          0.1428479 ,  0.02759788],\n",
       "        [-0.01745305,  0.04344401, -0.01062486, ..., -0.03263511,\n",
       "          0.03333901, -0.03742057],\n",
       "        ...,\n",
       "        [-0.04539689, -0.04439959,  0.02818057, ..., -0.0380819 ,\n",
       "         -0.03852956, -0.01856288],\n",
       "        [ 0.02871126, -0.03469737,  0.02487052, ...,  0.03580599,\n",
       "          0.00650898,  0.02794788],\n",
       "        [-0.01308306, -0.04385605, -0.0404823 , ...,  0.04515317,\n",
       "         -0.03049865, -0.00236553]], dtype=float32)>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(512, 512) dtype=float32, numpy=\n",
       " array([[ 0.02826669,  0.00403106, -0.01311948, ..., -0.03972981,\n",
       "          0.04139782,  0.00284072],\n",
       "        [-0.02889937, -0.00842795, -0.05242063, ..., -0.02213012,\n",
       "         -0.05835016,  0.04838712],\n",
       "        [-0.02751839,  0.02743426,  0.03543394, ...,  0.03711938,\n",
       "          0.04191923,  0.00186694],\n",
       "        ...,\n",
       "        [-0.00934493, -0.02428775,  0.0327517 , ...,  0.01174346,\n",
       "          0.03933082, -0.02061581],\n",
       "        [-0.00998303, -0.00678154, -0.04082564, ..., -0.0480931 ,\n",
       "         -0.0331788 , -0.03586472],\n",
       "        [-0.03325773,  0.03100166, -0.03432865, ..., -0.00882358,\n",
       "         -0.02003407,  0.02556301]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([-0.00588298, -0.00555243, -0.00874058, -0.00804776,  0.02489052,\n",
       "         0.04347772, -0.01089829, -0.00379265, -0.00741418,  0.02766374,\n",
       "        -0.00201911,  0.02268543, -0.00670912, -0.00577114, -0.00615372,\n",
       "        -0.00517396,  0.0238504 , -0.00887859, -0.00617907,  0.05495219,\n",
       "         0.02205603, -0.00525092, -0.00840412,  0.00845519, -0.00577254,\n",
       "        -0.00599917, -0.00599922, -0.00598703, -0.00696469, -0.0060038 ,\n",
       "        -0.00941256, -0.00642604, -0.00803185,  0.02191368, -0.00665927,\n",
       "        -0.00570447, -0.00555647, -0.02304964, -0.01089037, -0.00379091,\n",
       "        -0.00534248, -0.00680044,  0.06323448,  0.04596302,  0.05536022,\n",
       "        -0.00509295,  0.04264591, -0.01538482,  0.03012734, -0.00873443,\n",
       "        -0.00990621, -0.00634713,  0.04253669, -0.00631605, -0.00697265,\n",
       "        -0.01034094, -0.00699166,  0.02158245, -0.00950466, -0.01062364,\n",
       "        -0.0059961 ,  0.05368553,  0.04045632, -0.00686648, -0.01405536,\n",
       "        -0.00381237, -0.00824254, -0.00673055,  0.011641  , -0.0098171 ,\n",
       "        -0.01114321,  0.05231787, -0.0063362 , -0.01049905, -0.00695431,\n",
       "        -0.00896529, -0.00745224, -0.00810126, -0.01914429, -0.00107818,\n",
       "        -0.00522397,  0.04183227,  0.02717226,  0.02025732, -0.00908914,\n",
       "        -0.00516201,  0.03271021,  0.03630141, -0.00697595,  0.03113354,\n",
       "        -0.00644879,  0.0292253 , -0.00559888,  0.04395057, -0.00600211,\n",
       "        -0.00642989, -0.00600415, -0.00740395, -0.00675215, -0.00736673,\n",
       "         0.02971877, -0.02234049, -0.00600302, -0.00797048, -0.0074956 ,\n",
       "         0.03625999, -0.00599863, -0.00978279, -0.01155947, -0.00600344,\n",
       "         0.03855273, -0.00555633, -0.0028843 , -0.00515716, -0.00682458,\n",
       "        -0.01212939, -0.00766748,  0.02146602, -0.00656918, -0.00452016,\n",
       "         0.03497868, -0.00600189,  0.04307909, -0.00510579, -0.00884152,\n",
       "         0.0315702 , -0.00440833, -0.0069233 , -0.00898351, -0.01221632,\n",
       "         0.02867526,  0.05082843, -0.00610529,  0.02022855, -0.00280412,\n",
       "        -0.02780823, -0.00527447,  0.06335655,  0.        ,  0.0220787 ,\n",
       "        -0.00525074, -0.00680658, -0.00600195,  0.03270497, -0.00242125,\n",
       "        -0.00983515,  0.03206827,  0.05364316,  0.0250036 , -0.00373429,\n",
       "        -0.00748277, -0.00600147,  0.02386699,  0.03087247,  0.03931982,\n",
       "        -0.00980381,  0.02665936, -0.00599436, -0.00381855, -0.00554491,\n",
       "        -0.00743759,  0.04959151, -0.00673594, -0.0059827 ,  0.02736525,\n",
       "        -0.00796947, -0.00606763, -0.00699434,  0.01202353, -0.00476871,\n",
       "        -0.00405413, -0.00604916,  0.02665697, -0.00518943,  0.03085333,\n",
       "        -0.03273031,  0.00138951, -0.00321106, -0.00898364, -0.00909612,\n",
       "        -0.00696224, -0.00817214,  0.02501861, -0.01049199, -0.0060045 ,\n",
       "        -0.00764117, -0.01031219, -0.01089394, -0.00973746, -0.00921705,\n",
       "        -0.00678644,  0.        , -0.00401198, -0.0054564 , -0.00956323,\n",
       "        -0.0203325 , -0.00745121, -0.00425704, -0.00531877, -0.00728661,\n",
       "        -0.00480749,  0.02473527, -0.00600031, -0.00820281, -0.0020236 ,\n",
       "        -0.00600381, -0.00694148, -0.00641144, -0.00501307,  0.04088297,\n",
       "        -0.00600304, -0.00600008, -0.0078464 , -0.00655127, -0.00254294,\n",
       "        -0.00200906,  0.03310957, -0.02102788,  0.0218215 ,  0.03123897,\n",
       "        -0.01344536, -0.00481261, -0.00554181, -0.02668726, -0.00393835,\n",
       "        -0.00951387, -0.00753182, -0.00585391, -0.00559047, -0.00641618,\n",
       "        -0.00227399, -0.00922059, -0.00750334,  0.04830964, -0.00912183,\n",
       "        -0.00250247,  0.04176621, -0.00590529, -0.00773767, -0.00535289,\n",
       "         0.04065926, -0.00895183, -0.01100853,  0.03809579, -0.00398101,\n",
       "        -0.00837992, -0.00429977, -0.01204355, -0.00679984, -0.00596643,\n",
       "        -0.00727457, -0.00422962,  0.03929926, -0.00808793, -0.00849973,\n",
       "        -0.00960898, -0.00664617, -0.00830406, -0.00871811,  0.05486784,\n",
       "        -0.00584838, -0.00326308, -0.00461468, -0.00886259, -0.00719379,\n",
       "         0.03715229, -0.00608559, -0.00648809, -0.01236934, -0.00678767,\n",
       "         0.04793188, -0.00755491, -0.00645138, -0.01788255,  0.05764446,\n",
       "         0.02195447, -0.0061407 ,  0.03187963, -0.00600265, -0.00599847,\n",
       "        -0.00549244, -0.00600444, -0.01135891,  0.02707677, -0.00961116,\n",
       "        -0.00722558, -0.01023538, -0.00798922, -0.00959417,  0.01565542,\n",
       "        -0.00604865, -0.00847771,  0.02205134, -0.0069872 ,  0.02116849,\n",
       "         0.03004081, -0.00525406, -0.02135946,  0.03099757,  0.01364638,\n",
       "         0.02448739, -0.00706365,  0.04781551,  0.01025117,  0.03050387,\n",
       "         0.01133748, -0.0054934 , -0.01114874,  0.03357792,  0.02354514,\n",
       "        -0.00730743,  0.03689712, -0.00935194, -0.00565835, -0.00757857,\n",
       "        -0.00748329, -0.01058007, -0.00978362, -0.0041351 ,  0.05642421,\n",
       "         0.04159309, -0.01081214,  0.02891592, -0.0048751 , -0.00392212,\n",
       "        -0.00534583,  0.03644023, -0.00513681,  0.05347473, -0.00167565,\n",
       "         0.04568428,  0.04533285,  0.02671668,  0.02845699, -0.01728022,\n",
       "        -0.00321998, -0.00600385, -0.00699386, -0.00543605, -0.01035626,\n",
       "        -0.00459268, -0.00600117,  0.03547743, -0.01610604,  0.05733471,\n",
       "        -0.00747209, -0.00683127, -0.00554833,  0.01300628, -0.00248058,\n",
       "        -0.00599787,  0.02878017,  0.03376589, -0.00665675,  0.02908578,\n",
       "        -0.00621868, -0.00600214, -0.00990542, -0.00717629, -0.00599412,\n",
       "        -0.00577033, -0.00331767, -0.00568894, -0.00892137, -0.0065471 ,\n",
       "        -0.00575751, -0.0109916 , -0.00512121,  0.02734822, -0.0079235 ,\n",
       "        -0.00767833, -0.00983635, -0.02309692,  0.0006665 , -0.02191101,\n",
       "         0.06585213,  0.00912447, -0.00657073, -0.00361623, -0.00980333,\n",
       "         0.03976916,  0.04061291, -0.02220752, -0.00663791, -0.00510569,\n",
       "        -0.014018  , -0.02218699, -0.0059972 , -0.00372951,  0.03499292,\n",
       "         0.03143987, -0.00389152, -0.00935004,  0.03709335,  0.05581949,\n",
       "        -0.00600388, -0.0063967 , -0.01311145, -0.00599838,  0.04933486,\n",
       "         0.05040467,  0.02544606, -0.00817544,  0.03794609, -0.01448236,\n",
       "        -0.0051936 ,  0.01736142, -0.00129561,  0.04809993, -0.0089014 ,\n",
       "        -0.00492352, -0.00863163, -0.00533921,  0.03896284, -0.00798304,\n",
       "        -0.00998337,  0.05573278,  0.02854   , -0.00600251,  0.02930533,\n",
       "        -0.00949914, -0.00600326,  0.04385958, -0.00578051, -0.00643373,\n",
       "        -0.02464864, -0.00600281,  0.03452238, -0.00847096, -0.00778507,\n",
       "        -0.01852557, -0.00699401, -0.00599917,  0.03967309, -0.00450292,\n",
       "        -0.0094987 , -0.00598602, -0.00600306, -0.0064147 ,  0.03768791,\n",
       "        -0.01119372,  0.01581609,  0.0251035 ,  0.05095962, -0.02261356,\n",
       "        -0.01525462,  0.02413092, -0.00600194, -0.03000521, -0.01022832,\n",
       "        -0.00687016, -0.00447216,  0.03176596, -0.00299361, -0.00221997,\n",
       "         0.04454124, -0.00600059, -0.00540192, -0.00528333, -0.00600022,\n",
       "        -0.00788455, -0.00597496,  0.02496506,  0.04820425, -0.0111319 ,\n",
       "        -0.00775386, -0.03310069, -0.01141772, -0.0089226 , -0.00472186,\n",
       "        -0.00839165, -0.02819584,  0.01063437, -0.01629498, -0.00232415,\n",
       "        -0.00630425, -0.00666338, -0.00768154,  0.01117968,  0.02890145,\n",
       "        -0.00513721, -0.00583549,  0.03830193, -0.00283565,  0.07812671,\n",
       "        -0.02139368, -0.0017776 ,  0.03641272,  0.02151743, -0.00777499,\n",
       "        -0.00889963, -0.00415385,  0.034769  , -0.0095515 ,  0.03754536,\n",
       "        -0.0071652 , -0.00799374, -0.00370269,  0.05121187, -0.00169656,\n",
       "         0.03848371, -0.01100998,  0.02752761, -0.00964294,  0.0132446 ,\n",
       "         0.01293534, -0.00768705, -0.0055473 , -0.00979165, -0.00681467,\n",
       "        -0.00585102,  0.02002832], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(512, 10) dtype=float32, numpy=\n",
       " array([[ 0.0848022 ,  0.0729403 ,  0.06603347, ...,  0.0092035 ,\n",
       "          0.04360691, -0.05299713],\n",
       "        [ 0.00926486, -0.08881786, -0.09380419, ...,  0.02562462,\n",
       "         -0.04436143, -0.05547628],\n",
       "        [ 0.0221125 , -0.00481457, -0.07740803, ...,  0.06201437,\n",
       "          0.02861257, -0.01147637],\n",
       "        ...,\n",
       "        [ 0.03680316,  0.05553249, -0.05158028, ...,  0.03622943,\n",
       "         -0.0933435 ,  0.07693174],\n",
       "        [-0.01310642,  0.09372533,  0.03674053, ...,  0.05892043,\n",
       "         -0.08517819, -0.08326041],\n",
       "        [ 0.05169842, -0.15601689,  0.05726849, ...,  0.06900553,\n",
       "          0.00903515, -0.0376115 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([-0.0080003 , -0.08871356,  0.08154257, -0.05666733, -0.05714251,\n",
       "        -0.0173965 , -0.03111394,  0.00675338, -0.04737844, -0.00386761],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.weights\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(model.get_weights()[0].ravel(),100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSTM\n",
    "\n",
    "Using Fake news classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Import Key Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hassan.sherwani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Loading and preparing data\n",
    "\n",
    "- Dataset: https://www.kaggle.com/c/fake-news/data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Drop Nan Values\n",
    "df=df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ready_data.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('ready_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Independent Features\n",
    "\n",
    "X=df[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Dependent features\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 1)\n",
      "(18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.Corpus building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(titles)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', titles['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.One_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3195, 3819, 4115, 1834, 2587, 4313, 130, 3405, 2223, 4196],\n",
       " [1470, 1467, 3099, 2281, 16, 74, 116],\n",
       " [729, 1932, 358, 1021],\n",
       " [3298, 4722, 4900, 3569, 2532, 3155],\n",
       " [3655, 16, 3521, 4383, 4492, 696, 16, 907, 397, 1049]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Vocabulary size\n",
    "voc_size=5000\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
    "onehot_repr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[hous dem aid even see comey letter jason chaffetz tweet] is encoded as\n",
    "\n",
    "[2620, 3271, 469, 1972, 4408, 2180, 4327, 2937, 2257, 2824]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0 3195 3819 4115 1834\n",
      "  2587 4313  130 3405 2223 4196]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0 1470\n",
      "  1467 3099 2281   16   74  116]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0  729 1932  358 1021]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  3298 4722 4900 3569 2532 3155]\n",
      " [   0    0    0    0    0    0    0    0    0    0 3655   16 3521 4383\n",
      "  4492  696   16  907  397 1049]]\n"
     ]
    }
   ],
   "source": [
    "#padding\n",
    "sent_length=20\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sentence lenth is 20 and our 1st sentence has 10 words. So all other words are padded as zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features=40 # dimension of embedding layer\n",
    "voc_size=5000\n",
    "sent_length=20\n",
    "output_layer= 1 \n",
    "epochs=10\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Defining basic model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(LSTM(100)) # one lstm layer with 100 neurons\n",
    "model.add(Dense(output_layer,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary params calculation\n",
    "\n",
    "https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are three steps:**\n",
    "\n",
    "- For embedding layer: Dim of embedded layer(40) * vocab_size(5000)\n",
    "\n",
    "- For LSTM Layer: Now formula is **#of params=g*[h(h+i)+biase]**\n",
    "\n",
    "where g=lstm layer length i.e 1. For FFNS, RNN has 1 , LSTM has 4 and GRU has 3 layers<br>\n",
    "h=hidden layer size (number of neurons in hidden layer) i.e 100<br> \n",
    "i=Input size/dimension i.e embedding_vector_features that is coming as an input on lstm layer in step2 (40 is value) <br>\n",
    "biase= 100 of neurons for outpt of lstm layer\n",
    "\n",
    "**4*[100(100+40)+100]**\n",
    "\n",
    "- For Dense (Output): lstm layer acting as input(100) * neurons in output layer(1) + biase(1 as there is only one neuron in output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, (18285,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs),y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 20)\n",
      "(18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape)\n",
    "print(y_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.split train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14628 samples, validate on 3657 samples\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 6s 395us/sample - loss: 0.3134 - accuracy: 0.8558 - val_loss: 0.2000 - val_accuracy: 0.9073\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.1365 - accuracy: 0.9476 - val_loss: 0.2090 - val_accuracy: 0.9111\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 3s 233us/sample - loss: 0.1004 - accuracy: 0.9645 - val_loss: 0.2174 - val_accuracy: 0.9139\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.0761 - accuracy: 0.9716 - val_loss: 0.2724 - val_accuracy: 0.9136\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 3s 236us/sample - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.2842 - val_accuracy: 0.9103\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.3406 - val_accuracy: 0.9141\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 3s 239us/sample - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.3583 - val_accuracy: 0.9106\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 3s 238us/sample - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.4029 - val_accuracy: 0.9171\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 4s 241us/sample - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.4420 - val_accuracy: 0.9117\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 4s 243us/sample - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.5177 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d4026b808>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1864,  218],\n",
       "       [ 100, 1475]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.adding dropout\n",
    "\n",
    "results are sligtly improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model_dropout=Sequential()\n",
    "model_dropout.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model_dropout.add(Dropout(0.3))\n",
    "model_dropout.add(LSTM(100))\n",
    "model_dropout.add(Dropout(0.3))\n",
    "model_dropout.add(Dense(1,activation='sigmoid'))\n",
    "model_dropout.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model_dropout.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14628 samples, validate on 3657 samples\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 6s 395us/sample - loss: 0.3130 - accuracy: 0.8536 - val_loss: 0.2012 - val_accuracy: 0.9103\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.1437 - accuracy: 0.9442 - val_loss: 0.1955 - val_accuracy: 0.9122\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 3s 234us/sample - loss: 0.1076 - accuracy: 0.9607 - val_loss: 0.2070 - val_accuracy: 0.9161\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 4s 239us/sample - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.2238 - val_accuracy: 0.9144\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 3s 235us/sample - loss: 0.0661 - accuracy: 0.9769 - val_loss: 0.2855 - val_accuracy: 0.9171\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 3s 238us/sample - loss: 0.0543 - accuracy: 0.9806 - val_loss: 0.2931 - val_accuracy: 0.9163\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 3s 239us/sample - loss: 0.0397 - accuracy: 0.9871 - val_loss: 0.2892 - val_accuracy: 0.9180\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 4s 242us/sample - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.3388 - val_accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 4s 242us/sample - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.3890 - val_accuracy: 0.9163\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 4s 242us/sample - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.4176 - val_accuracy: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d47eab608>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model_dropout.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179655455291222"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.Using EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14628 samples, validate on 3657 samples\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 3s 232us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.5029 - val_accuracy: 0.9103\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 3s 232us/sample - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.6246 - val_accuracy: 0.9046\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 3s 235us/sample - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.5204 - val_accuracy: 0.9070\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 3s 234us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.7130 - val_accuracy: 0.9119\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_data=(X_test,y_test),callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9119496855345912"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2082\n",
      "           1       0.89      0.91      0.90      1575\n",
      "\n",
      "    accuracy                           0.91      3657\n",
      "   macro avg       0.91      0.91      0.91      3657\n",
      "weighted avg       0.91      0.91      0.91      3657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1901  181]\n",
      " [ 141 1434]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import scikitplot as skplt\n",
    "plt.figure(figsize=(10,10))\n",
    "skplt.metrics.plot_confusion_matrix(y_test,y_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

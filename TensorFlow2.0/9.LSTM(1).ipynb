{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing LSTM\n",
    "\n",
    "Using Fake news classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Import Key Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hassan.sherwani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Loading and preparing data\n",
    "\n",
    "- Dataset: https://www.kaggle.com/c/fake-news/data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Drop Nan Values\n",
    "df=df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ready_data.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('ready_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Independent Features\n",
    "\n",
    "X=df[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Dependent features\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 1)\n",
      "(18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.Corpus building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(0, len(titles)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', titles['title'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.One_hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3195, 3819, 4115, 1834, 2587, 4313, 130, 3405, 2223, 4196],\n",
       " [1470, 1467, 3099, 2281, 16, 74, 116],\n",
       " [729, 1932, 358, 1021],\n",
       " [3298, 4722, 4900, 3569, 2532, 3155],\n",
       " [3655, 16, 3521, 4383, 4492, 696, 16, 907, 397, 1049]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Vocabulary size\n",
    "voc_size=5000\n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
    "onehot_repr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[hous dem aid even see comey letter jason chaffetz tweet] is encoded as\n",
    "\n",
    "[2620, 3271, 469, 1972, 4408, 2180, 4327, 2937, 2257, 2824]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0 3195 3819 4115 1834\n",
      "  2587 4313  130 3405 2223 4196]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0 1470\n",
      "  1467 3099 2281   16   74  116]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0  729 1932  358 1021]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "  3298 4722 4900 3569 2532 3155]\n",
      " [   0    0    0    0    0    0    0    0    0    0 3655   16 3521 4383\n",
      "  4492  696   16  907  397 1049]]\n"
     ]
    }
   ],
   "source": [
    "#padding\n",
    "sent_length=20\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that sentence lenth is 20 and our 1st sentence has 10 words. So all other words are padded as zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features=40 # dimension of embedding layer\n",
    "voc_size=5000\n",
    "sent_length=20\n",
    "output_layer= 1 \n",
    "epochs=10\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Defining basic model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(LSTM(100)) # one lstm layer with 100 neurons\n",
    "model.add(Dense(output_layer,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary params calculation\n",
    "\n",
    "https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are three steps:**\n",
    "\n",
    "- For embedding layer: Dim of embedded layer(40) * vocab_size(5000)\n",
    "\n",
    "- For LSTM Layer: Now formula is **#of params=g*[h(h+i)+biase]**\n",
    "\n",
    "where g=lstm layer length i.e 1. For FFNS, RNN has 1 , LSTM has 4 and GRU has 3 layers<br>\n",
    "h=hidden layer size (number of neurons in hidden layer) i.e 100<br> \n",
    "i=Input size/dimension i.e embedding_vector_features that is coming as an input on lstm layer in step2 (40 is value) <br>\n",
    "biase= 100 of neurons for outpt of lstm layer\n",
    "\n",
    "**4*[100(100+40)+100]**\n",
    "\n",
    "- For Dense (Output): lstm layer acting as input(100) * neurons in output layer(1) + biase(1 as there is only one neuron in output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18285, (18285,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_docs),y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285, 20)\n",
      "(18285,)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape)\n",
    "print(y_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.split train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14628 samples, validate on 3657 samples\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 6s 395us/sample - loss: 0.3134 - accuracy: 0.8558 - val_loss: 0.2000 - val_accuracy: 0.9073\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.1365 - accuracy: 0.9476 - val_loss: 0.2090 - val_accuracy: 0.9111\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 3s 233us/sample - loss: 0.1004 - accuracy: 0.9645 - val_loss: 0.2174 - val_accuracy: 0.9139\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.0761 - accuracy: 0.9716 - val_loss: 0.2724 - val_accuracy: 0.9136\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 3s 236us/sample - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.2842 - val_accuracy: 0.9103\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.3406 - val_accuracy: 0.9141\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 3s 239us/sample - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.3583 - val_accuracy: 0.9106\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 3s 238us/sample - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.4029 - val_accuracy: 0.9171\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 4s 241us/sample - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.4420 - val_accuracy: 0.9117\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 4s 243us/sample - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.5177 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d4026b808>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1864,  218],\n",
       "       [ 100, 1475]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9130434782608695"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.adding dropout\n",
    "\n",
    "results are sligtly improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 40)            200000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 40)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               56400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 256,501\n",
      "Trainable params: 256,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model_dropout=Sequential()\n",
    "model_dropout.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model_dropout.add(Dropout(0.3))\n",
    "model_dropout.add(LSTM(100))\n",
    "model_dropout.add(Dropout(0.3))\n",
    "model_dropout.add(Dense(1,activation='sigmoid'))\n",
    "model_dropout.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model_dropout.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14628 samples, validate on 3657 samples\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 6s 395us/sample - loss: 0.3130 - accuracy: 0.8536 - val_loss: 0.2012 - val_accuracy: 0.9103\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 3s 237us/sample - loss: 0.1437 - accuracy: 0.9442 - val_loss: 0.1955 - val_accuracy: 0.9122\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 3s 234us/sample - loss: 0.1076 - accuracy: 0.9607 - val_loss: 0.2070 - val_accuracy: 0.9161\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 4s 239us/sample - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.2238 - val_accuracy: 0.9144\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 3s 235us/sample - loss: 0.0661 - accuracy: 0.9769 - val_loss: 0.2855 - val_accuracy: 0.9171\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 3s 238us/sample - loss: 0.0543 - accuracy: 0.9806 - val_loss: 0.2931 - val_accuracy: 0.9163\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 3s 239us/sample - loss: 0.0397 - accuracy: 0.9871 - val_loss: 0.2892 - val_accuracy: 0.9180\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 4s 242us/sample - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.3388 - val_accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 4s 242us/sample - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.3890 - val_accuracy: 0.9163\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 4s 242us/sample - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.4176 - val_accuracy: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d47eab608>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=epochs,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model_dropout.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9179655455291222"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.Using EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13165 samples, validate on 1463 samples\n",
      "Epoch 1/10\n",
      "13165/13165 [==============================] - 3s 231us/sample - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0085 - val_accuracy: 0.9973\n",
      "Epoch 2/10\n",
      "13165/13165 [==============================] - 3s 235us/sample - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0161 - val_accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "13165/13165 [==============================] - 3s 233us/sample - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0180 - val_accuracy: 0.9932\n",
      "Epoch 4/10\n",
      "13165/13165 [==============================] - 3s 228us/sample - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0240 - val_accuracy: 0.9904\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict_classes(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9144107191687175"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      2082\n",
      "           1       0.88      0.93      0.90      1575\n",
      "\n",
      "    accuracy                           0.91      3657\n",
      "   macro avg       0.91      0.92      0.91      3657\n",
      "weighted avg       0.92      0.91      0.91      3657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1884  198]\n",
      " [ 115 1460]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import scikitplot as skplt\n",
    "plt.figure(figsize=(10,10))\n",
    "skplt.metrics.plot_confusion_matrix(y_test,y_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
